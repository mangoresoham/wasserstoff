{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyPDF2\n",
    "\n",
    "# # Function to extract text from PDF using PyPDF2\n",
    "# def extract_text_from_pdf(file_path):\n",
    "#     text = ''\n",
    "#     with open(file_path, 'rb') as file:\n",
    "#         pdf_reader = PyPDF2.PdfReader(file)\n",
    "#         for page_num in range(len(pdf_reader.pages)):\n",
    "#             page = pdf_reader.pages[page_num]\n",
    "#             text += page.extract_text()\n",
    "#     return text\n",
    "\n",
    "# # Example usage\n",
    "# pdf_file_path = \"D:\\Programming\\Projects\\WASSERSTOFF\\Data\\pdf1.pdf\"  # Replace with your PDF file path\n",
    "# document_text = extract_text_from_pdf(pdf_file_path)\n",
    "\n",
    "# # Check the extracted text\n",
    "# len(document_text)  # Print first 1000 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_text=\"\"\"\n",
    "\n",
    "In a world increasingly defined by technology, the relationship between humans and machines has become a focal point of discussion across various domains. The advent of artificial intelligence (AI) has reshaped industries, impacting everything from healthcare to finance, education to entertainment. With the integration of AI in daily life, there emerges a profound question: what does it mean to be human in an age where machines can replicate cognitive functions? This question is particularly relevant in the realm of healthcare, where AI systems are not only assisting doctors in diagnosing diseases but also in predicting patient outcomes based on vast datasets. As a result, the medical community is witnessing a shift in how care is delivered; physicians are now seen as guides who interpret AI-generated insights rather than sole decision-makers. This paradigm shift has its proponents and critics. Advocates argue that AI enhances human capabilities, allowing for more accurate diagnoses and personalized treatment plans. They cite examples of AI systems that analyze medical images with a precision that rivals expert radiologists, thus improving early detection rates of conditions like cancer. On the other hand, critics voice concerns regarding the ethical implications of relying too heavily on machines, fearing that this could undermine the human touch that is integral to patient care. They point out the risk of data bias, as AI systems trained on historical data may perpetuate existing inequalities in healthcare delivery. Moreover, there are apprehensions about patient privacy, as the use of sensitive health data raises questions about who owns this information and how it is used. As healthcare continues to evolve in this direction, the dialogue surrounding the intersection of technology and human experience becomes even more critical. Moving beyond healthcare, the influence of AI permeates other sectors such as finance, where algorithms determine credit scores and assess loan applications. The automation of these processes promises efficiency and speed, yet it also poses significant challenges. For instance, the opaque nature of algorithmic decision-making can lead to a lack of accountability, making it difficult for individuals to understand why they were denied a loan or insurance coverage. In response, policymakers are grappling with the need to regulate AI to ensure fairness and transparency. The challenge lies in striking a balance between innovation and safeguarding the rights of individuals, a debate that reflects broader societal concerns about the pace of technological advancement. In the realm of education, AI offers tools for personalized learning experiences, adapting curricula to meet the unique needs of each student. This potential for customization is promising, particularly for learners who may struggle in traditional educational settings. However, the reliance on technology raises questions about equity, as not all students have equal access to the necessary tools and resources. The digital divide becomes apparent, highlighting disparities that exist within and between communities. As educators explore the integration of AI in classrooms, they must also consider how to ensure that all students benefit from these innovations. In the creative industries, AI is reshaping the landscape of art, music, and literature. Tools powered by AI are now capable of generating original works, blurring the lines between human creativity and machine-generated content. This evolution prompts discussions about authorship and originality. If a machine creates a piece of art, who is the true artist? Furthermore, the rise of deepfakes and AI-generated media has raised ethical concerns about misinformation and the manipulation of public perception. As technology continues to advance, society faces the dual challenge of embracing innovation while mitigating its risks. The overarching theme across these sectors is the need for a thoughtful approach to AI integration, one that considers the ethical, social, and economic implications of these powerful technologies. The dialogue surrounding AI is not merely academic; it has real-world consequences that affect individuals, communities, and global dynamics. As we stand on the precipice of a future increasingly influenced by artificial intelligence, it is crucial that we engage in ongoing discussions about what it means to live in harmony with machines. The future of work, society, and human interaction hinges on our ability to navigate these complexities with care, foresight, and a commitment to preserving the values that define our humanity. Ultimately, the integration of AI into everyday life challenges us to redefine our roles as individuals and as a society, prompting us to ask profound questions about identity, ethics, and the nature of progress. In this ever-evolving landscape, we must prioritize education, policy development, and ethical considerations to ensure that technology serves as a tool for enhancing human potential rather than a force that diminishes it.\n",
    "\"\"\"\n",
    "\n",
    "reference_summary = \"\"\"\n",
    "The relationship between humans and machines is increasingly defined by the rise of artificial intelligence (AI), impacting various sectors, including healthcare, finance, education, and the creative industries. In healthcare, AI assists in diagnosing diseases and predicting outcomes, prompting discussions about the balance between technology and the human touch in patient care. While proponents argue that AI enhances capabilities, critics raise concerns about data bias, patient privacy, and the potential loss of human empathy. In finance, AI streamlines processes but introduces challenges related to transparency and accountability. The education sector benefits from personalized learning tools, though disparities in access highlight existing inequalities. In creative fields, AI-generated content raises questions about authorship and originality, particularly concerning misinformation. The overarching theme is the necessity for a thoughtful approach to AI integration, balancing innovation with ethical and social implications. As society navigates these complexities, ongoing dialogue is essential to ensure technology enhances human potential while preserving core values.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sumy\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the integration of AI in daily life, there emerges a profound question: what does it mean to be human in an age where machines can replicate cognitive functions? Moreover, there are apprehensions about patient privacy, as the use of sensitive health data raises questions about who owns this information and how it is used. As technology continues to advance, society faces the dual challenge of embracing innovation while mitigating its risks. As we stand on the precipice of a future increasingly influenced by artificial intelligence, it is crucial that we engage in ongoing discussions about what it means to live in harmony with machines. In this ever-evolving landscape, we must prioritize education, policy development, and ethical considerations to ensure that technology serves as a tool for enhancing human potential rather than a force that diminishes it.\n"
     ]
    }
   ],
   "source": [
    "# For Strings\n",
    "parser = PlaintextParser.from_string(document_text,Tokenizer(\"english\"))\n",
    "final_summary=[]\n",
    "\n",
    "summarizer = LexRankSummarizer()\n",
    "#Summarize the document with 2 sentences\n",
    "summary = summarizer(parser.document, 5)\n",
    "\n",
    "for sentence in summary:\n",
    "    final_summary.append(str(sentence))  # Convert each sentence to a string\n",
    "\n",
    "# Convert final_summary to a single string if needed\n",
    "final_summary_text = ' '.join(final_summary)\n",
    "\n",
    "print(final_summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score with smoothing: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mango\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# Make sure to download the necessary NLTK resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sample reference text\n",
    "reference_text = reference_summary\n",
    "\n",
    "# Sample generated text from your model\n",
    "generated_text = final_summary_text\n",
    "\n",
    "# Tokenize the reference and generated texts\n",
    "reference = [nltk.word_tokenize(reference_summary.lower())]  # List of reference sentences\n",
    "generated = nltk.word_tokenize(generated_text.lower())\n",
    "\n",
    "# Use a smoothing function\n",
    "smoothie = SmoothingFunction()\n",
    "bleu_score = sentence_bleu(reference, generated, smoothing_function=smoothie.method1)\n",
    "\n",
    "print(f\"BLEU score with smoothing: {bleu_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score with smoothing: 0.0194\n",
      "BLEU score (unigrams with smoothing): 0.3443\n",
      "BLEU score (bigrams with smoothing): 0.0660\n",
      "BLEU score (trigrams with smoothing): 0.0111\n",
      "BLEU score (4-grams with smoothing): 0.0006\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# Sample reference text\n",
    "reference_text = reference_summary\n",
    "\n",
    "# Sample generated text from your model\n",
    "generated_text = final_summary_text\n",
    "\n",
    "# Tokenize the reference and generated texts\n",
    "reference = [nltk.word_tokenize(reference_text.lower())]  # List of reference sentences\n",
    "generated = nltk.word_tokenize(generated_text.lower())\n",
    "\n",
    "# Use a smoothing function\n",
    "smoothie = SmoothingFunction()\n",
    "\n",
    "# Calculate BLEU score with smoothing for all n-gram orders\n",
    "bleu_score = sentence_bleu(reference, generated, smoothing_function=smoothie.method1)\n",
    "print(f\"BLEU score with smoothing: {bleu_score:.4f}\")\n",
    "\n",
    "# Calculate BLEU score for unigrams, bigrams, trigrams, and 4-grams with smoothing\n",
    "bleu_score_unigrams = sentence_bleu(reference, generated, weights=(1, 0, 0, 0), smoothing_function=smoothie.method1)\n",
    "bleu_score_bigrams = sentence_bleu(reference, generated, weights=(0, 1, 0, 0), smoothing_function=smoothie.method1)\n",
    "bleu_score_trigrams = sentence_bleu(reference, generated, weights=(0, 0, 1, 0), smoothing_function=smoothie.method1)\n",
    "bleu_score_4grams = sentence_bleu(reference, generated, weights=(0, 0, 0, 1), smoothing_function=smoothie.method1)\n",
    "\n",
    "print(f\"BLEU score (unigrams with smoothing): {bleu_score_unigrams:.4f}\")\n",
    "print(f\"BLEU score (bigrams with smoothing): {bleu_score_bigrams:.4f}\")\n",
    "print(f\"BLEU score (trigrams with smoothing): {bleu_score_trigrams:.4f}\")\n",
    "print(f\"BLEU score (4-grams with smoothing): {bleu_score_4grams:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=0.391304347826087, recall=0.34838709677419355, fmeasure=0.3686006825938567), 'rouge2': Score(precision=0.058394160583941604, recall=0.05194805194805195, fmeasure=0.05498281786941581), 'rougeL': Score(precision=0.1956521739130435, recall=0.17419354838709677, fmeasure=0.18430034129692835)}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Example summaries\n",
    "generated_summary = final_summary_text\n",
    "reference_summary = reference_summary\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(reference_summary, generated_summary)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1:\n",
      "  Precision: 0.3913\n",
      "  Recall: 0.3484\n",
      "  F-measure: 0.3686\n",
      "\n",
      "rouge2:\n",
      "  Precision: 0.0584\n",
      "  Recall: 0.0519\n",
      "  F-measure: 0.0550\n",
      "\n",
      "rougeL:\n",
      "  Precision: 0.1957\n",
      "  Recall: 0.1742\n",
      "  F-measure: 0.1843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each ROUGE score and print its values\n",
    "for key, score in scores.items():\n",
    "    print(f\"{key}:\")\n",
    "    print(f\"  Precision: {score.precision:.4f}\")\n",
    "    print(f\"  Recall: {score.recall:.4f}\")\n",
    "    print(f\"  F-measure: {score.fmeasure:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
