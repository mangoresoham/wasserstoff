{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyPDF2\n",
    "\n",
    "# # Function to extract text from PDF using PyPDF2\n",
    "# def extract_text_from_pdf(file_path):\n",
    "#     text = ''\n",
    "#     with open(file_path, 'rb') as file:\n",
    "#         pdf_reader = PyPDF2.PdfReader(file)\n",
    "#         for page_num in range(len(pdf_reader.pages)):\n",
    "#             page = pdf_reader.pages[page_num]\n",
    "#             text += page.extract_text()\n",
    "#     return text\n",
    "\n",
    "# # Example usage\n",
    "# pdf_file_path = \"C:/Users/mango/Documents/GitHub/PDF-summerizer/temp/pdf2.pdf\"  # Replace with your PDF file path\n",
    "# document_text = extract_text_from_pdf(pdf_file_path)\n",
    "\n",
    "# # Check the extracted text\n",
    "# print(document_text[:1000])  # Print first 1000 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_text=\"\"\"\n",
    "In a world increasingly defined by technology, the relationship between humans and machines has become a focal point of discussion across various domains. The advent of artificial intelligence (AI) has reshaped industries, impacting everything from healthcare to finance, education to entertainment. With the integration of AI in daily life, there emerges a profound question: what does it mean to be human in an age where machines can replicate cognitive functions? This question is particularly relevant in the realm of healthcare, where AI systems are not only assisting doctors in diagnosing diseases but also in predicting patient outcomes based on vast datasets. As a result, the medical community is witnessing a shift in how care is delivered; physicians are now seen as guides who interpret AI-generated insights rather than sole decision-makers. This paradigm shift has its proponents and critics. Advocates argue that AI enhances human capabilities, allowing for more accurate diagnoses and personalized treatment plans. They cite examples of AI systems that analyze medical images with a precision that rivals expert radiologists, thus improving early detection rates of conditions like cancer. On the other hand, critics voice concerns regarding the ethical implications of relying too heavily on machines, fearing that this could undermine the human touch that is integral to patient care. They point out the risk of data bias, as AI systems trained on historical data may perpetuate existing inequalities in healthcare delivery. Moreover, there are apprehensions about patient privacy, as the use of sensitive health data raises questions about who owns this information and how it is used. As healthcare continues to evolve in this direction, the dialogue surrounding the intersection of technology and human experience becomes even more critical. Moving beyond healthcare, the influence of AI permeates other sectors such as finance, where algorithms determine credit scores and assess loan applications. The automation of these processes promises efficiency and speed, yet it also poses significant challenges. For instance, the opaque nature of algorithmic decision-making can lead to a lack of accountability, making it difficult for individuals to understand why they were denied a loan or insurance coverage. In response, policymakers are grappling with the need to regulate AI to ensure fairness and transparency. The challenge lies in striking a balance between innovation and safeguarding the rights of individuals, a debate that reflects broader societal concerns about the pace of technological advancement. In the realm of education, AI offers tools for personalized learning experiences, adapting curricula to meet the unique needs of each student. This potential for customization is promising, particularly for learners who may struggle in traditional educational settings. However, the reliance on technology raises questions about equity, as not all students have equal access to the necessary tools and resources. The digital divide becomes apparent, highlighting disparities that exist within and between communities. As educators explore the integration of AI in classrooms, they must also consider how to ensure that all students benefit from these innovations. In the creative industries, AI is reshaping the landscape of art, music, and literature. Tools powered by AI are now capable of generating original works, blurring the lines between human creativity and machine-generated content. This evolution prompts discussions about authorship and originality. If a machine creates a piece of art, who is the true artist? Furthermore, the rise of deepfakes and AI-generated media has raised ethical concerns about misinformation and the manipulation of public perception. As technology continues to advance, society faces the dual challenge of embracing innovation while mitigating its risks. The overarching theme across these sectors is the need for a thoughtful approach to AI integration, one that considers the ethical, social, and economic implications of these powerful technologies. The dialogue surrounding AI is not merely academic; it has real-world consequences that affect individuals, communities, and global dynamics. As we stand on the precipice of a future increasingly influenced by artificial intelligence, it is crucial that we engage in ongoing discussions about what it means to live in harmony with machines. The future of work, society, and human interaction hinges on our ability to navigate these complexities with care, foresight, and a commitment to preserving the values that define our humanity. Ultimately, the integration of AI into everyday life challenges us to redefine our roles as individuals and as a society, prompting us to ask profound questions about identity, ethics, and the nature of progress. In this ever-evolving landscape, we must prioritize education, policy development, and ethical considerations to ensure that technology serves as a tool for enhancing human potential rather than a force that diminishes it.\n",
    "\"\"\"\n",
    "\n",
    "reference_summary = \"\"\"\n",
    "The relationship between humans and machines is increasingly defined by the rise of artificial intelligence (AI), impacting various sectors, including healthcare, finance, education, and the creative industries. In healthcare, AI assists in diagnosing diseases and predicting outcomes, prompting discussions about the balance between technology and the human touch in patient care. While proponents argue that AI enhances capabilities, critics raise concerns about data bias, patient privacy, and the potential loss of human empathy. In finance, AI streamlines processes but introduces challenges related to transparency and accountability. The education sector benefits from personalized learning tools, though disparities in access highlight existing inequalities. In creative fields, AI-generated content raises questions about authorship and originality, particularly concerning misinformation. The overarching theme is the necessity for a thoughtful approach to AI integration, balancing innovation with ethical and social implications. As society navigates these complexities, ongoing dialogue is essential to ensure technology enhances human potential while preserving core values.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary:**\n",
      "\n",
      "The document discusses the relationship between humans and machines in an increasingly technological world. It highlights the impact of artificial intelligence (AI) on various domains, including healthcare, finance, education, and creative industries. While AI has brought numerous benefits, such as improved diagnoses and personalized treatment plans in healthcare, it has also raised concerns about ethics, data bias, patient privacy, and the potential for machines to replicate human functions. The document emphasizes the need for a thoughtful approach to AI integration, considering the ethical, social, and economic implications of these technologies.\n",
      "\n",
      "**Domain of Document Text:**\n",
      "\n",
      "The primary domain of this document is Technology and Artificial Intelligence, with secondary domains in Healthcare, Finance, Education, and Social Ethics.\n",
      "\n",
      "**Domain-Specific Keywords:**\n",
      "\n",
      "1. Artifical Intelligence (AI)\n",
      "2. Machine Learning\n",
      "3. Data Science\n",
      "4. Healthcare Technology\n",
      "5. Personalized Medicine\n",
      "6. Biomedical Imaging\n",
      "7. Finance Technology\n",
      "8. Algorithmic Decision-Making\n",
      "9. Data Bias\n",
      "10. Patient Privacy\n",
      "11. Ethics in Technology\n",
      "12. Education Technology\n",
      "13. Personalized Learning\n",
      "14. Digital Divide\n",
      "15. Creative Industries\n",
      "16. Artificial Creativity\n",
      "17. Authorship\n",
      "18. Originality\n",
      "\n",
      "Note that some keywords may overlap between domains, but they are primarily categorized based on their relevance to the specific domain.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Summarize this document, Identify the domain of document text and list down domain specific keywords : {document_text}\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document discusses the relationship between humans and machines in an increasingly technological world. It highlights the impact of artificial intelligence (AI) on various domains, including healthcare, finance, education, and creative industries. While AI has brought numerous benefits, such as improved diagnoses and personalized treatment plans in healthcare, it has also raised concerns about ethics, data bias, patient privacy, and the potential for machines to replicate human functions. The document emphasizes the need for a thoughtful approach to AI integration, considering the ethical, social, and economic implications of these technologies.\n",
      "['Artifical Intelligence (AI)', 'Machine Learning', 'Data Science', 'Healthcare Technology', 'Personalized Medicine', 'Biomedical Imaging', 'Finance Technology', 'Algorithmic Decision-Making', 'Data Bias', 'Patient Privacy', 'Ethics in Technology', 'Education Technology', 'Personalized Learning', 'Digital Divide', 'Creative Industries', 'Artificial Creativity', 'Authorship', 'Originality', '', 'Note that some keywords may overlap between domains, but they are primarily categorized based on their relevance to the specific domain.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean and extract summary and keywords\n",
    "def clean_text(text):\n",
    "    \"\"\"Cleans the input text by removing extra spaces, line breaks, and formatting.\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Replace multiple spaces/newlines with a single space\n",
    "    text = re.sub(r'\\*\\*.*?\\*\\*', '', text)  # Remove bold markers like **Summary** or **Keywords**\n",
    "    return text\n",
    "\n",
    "def extract_summary_and_keywords(output_text):\n",
    "    \"\"\"Extracts and cleans the summary and keywords from the provided text.\"\"\"\n",
    "    # Extract the summary using regular expressions\n",
    "    summary_match = re.search(r'\\*\\*Summary:\\*\\*\\n(.*?)\\n\\n\\*\\*Domain', output_text, re.DOTALL)\n",
    "    summary = summary_match.group(1).strip() if summary_match else None\n",
    "    if summary:\n",
    "        summary = clean_text(summary)  # Clean the extracted summary\n",
    "\n",
    "    # Extract the keywords\n",
    "    keywords_match = re.search(r'\\*\\*Domain-Specific Keywords:\\*\\*\\n(.*?)$', output_text, re.DOTALL)\n",
    "    keywords_list = keywords_match.group(1).strip().split('\\n') if keywords_match else []\n",
    "    keywords = [re.sub(r'^\\d+\\.\\s*', '', keyword).strip() for keyword in keywords_list]  # Remove numbering\n",
    "    keywords = [clean_text(keyword) for keyword in keywords]  # Clean each keyword\n",
    "    \n",
    "    return summary, keywords\n",
    "\n",
    "# Call the function\n",
    "summary, keywords = extract_summary_and_keywords(output)\n",
    "\n",
    "# Output\n",
    "print(summary)\n",
    "print(keywords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROGUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=0.7111111111111111, recall=0.4129032258064516, fmeasure=0.5224489795918367), 'rouge2': Score(precision=0.3146067415730337, recall=0.18181818181818182, fmeasure=0.23045267489711935), 'rougeL': Score(precision=0.5444444444444444, recall=0.3161290322580645, fmeasure=0.39999999999999997)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Example summaries\n",
    "generated_summary = summary\n",
    "reference_summary = reference_summary\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(reference_summary, generated_summary)\n",
    "\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1:\n",
      "  Precision: 0.7111\n",
      "  Recall: 0.4129\n",
      "  F-measure: 0.5224\n",
      "\n",
      "rouge2:\n",
      "  Precision: 0.3146\n",
      "  Recall: 0.1818\n",
      "  F-measure: 0.2305\n",
      "\n",
      "rougeL:\n",
      "  Precision: 0.5444\n",
      "  Recall: 0.3161\n",
      "  F-measure: 0.4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each ROUGE score and print its values\n",
    "for key, score in scores.items():\n",
    "    print(f\"{key}:\")\n",
    "    print(f\"  Precision: {score.precision:.4f}\")\n",
    "    print(f\"  Recall: {score.recall:.4f}\")\n",
    "    print(f\"  F-measure: {score.fmeasure:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score with smoothing: 0.1829\n",
      "BLEU score (unigrams with smoothing): 0.3565\n",
      "BLEU score (bigrams with smoothing): 0.1919\n",
      "BLEU score (trigrams with smoothing): 0.1453\n",
      "BLEU score (4-grams with smoothing): 0.1125\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# Sample reference text\n",
    "reference_text = reference_summary\n",
    "\n",
    "# Sample generated text from your model\n",
    "generated_text = summary\n",
    "\n",
    "# Tokenize the reference and generated texts\n",
    "reference = [nltk.word_tokenize(reference_text.lower())]  # List of reference sentences\n",
    "generated = nltk.word_tokenize(generated_text.lower())\n",
    "\n",
    "# Use a smoothing function\n",
    "smoothie = SmoothingFunction()\n",
    "\n",
    "# Calculate BLEU score with smoothing for all n-gram orders\n",
    "bleu_score = sentence_bleu(reference, generated, smoothing_function=smoothie.method1)\n",
    "print(f\"BLEU score with smoothing: {bleu_score:.4f}\")\n",
    "\n",
    "# Calculate BLEU score for unigrams, bigrams, trigrams, and 4-grams with smoothing\n",
    "bleu_score_unigrams = sentence_bleu(reference, generated, weights=(1, 0, 0, 0), smoothing_function=smoothie.method1)\n",
    "bleu_score_bigrams = sentence_bleu(reference, generated, weights=(0, 1, 0, 0), smoothing_function=smoothie.method1)\n",
    "bleu_score_trigrams = sentence_bleu(reference, generated, weights=(0, 0, 1, 0), smoothing_function=smoothie.method1)\n",
    "bleu_score_4grams = sentence_bleu(reference, generated, weights=(0, 0, 0, 1), smoothing_function=smoothie.method1)\n",
    "\n",
    "print(f\"BLEU score (unigrams with smoothing): {bleu_score_unigrams:.4f}\")\n",
    "print(f\"BLEU score (bigrams with smoothing): {bleu_score_bigrams:.4f}\")\n",
    "print(f\"BLEU score (trigrams with smoothing): {bleu_score_trigrams:.4f}\")\n",
    "print(f\"BLEU score (4-grams with smoothing): {bleu_score_4grams:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
